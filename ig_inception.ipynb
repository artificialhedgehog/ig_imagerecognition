{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# A picture says more than a thousand hashtags\n",
    "\n",
    "Hashtags have show an impressive story: Were they in the beginning merely a tool to index freetext, the leading pound sign (yes, that's how it was called back in the days), has risen to become a symbol of a generation that can carry powerful political messages (It can also be used for way less impactful purposes, but that's a story for another rainy day). \n",
    "\n",
    "Coining a hashtag can have great benefits for political parties or companies: They offer a proxy to measure a product's or campaign's impact on social media and offer an easy tool to measure trends, geographical distribution and connotations.\n",
    "\n",
    "Sentiment analysis of tweets and other free-text messages is all abound, yet many users rely nowadays on photos to convey feelings and messages.\n",
    "\n",
    "Here I demonstrate how to use the Instagram API and image recognition to see what motifs users associate with a hashtag. We first download the pre-trained Inception V3 network, which is trained on ImageNet to recognize 1000 different concepts. Using Instagram's API, we load images that users annotated with a certain tag, e.g. a company slogan or a political statement. These images are then analyzed with the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tech\n",
    "\n",
    "Images are retrieved from [instagram](http://instagram.com) and then classified with Google's [Inception V3](https://www.tensorflow.org/tutorials/image_recognition) neural network.\n",
    "\n",
    "The implementation is built in Python, using _requests_, _PIL_ (resp. pillow for Python 3), and, of course, Tensorflow.\n",
    "\n",
    "> **A note on running this notebook:**\n",
    ">\n",
    "> It is recommended to install Tensorflow in a virtual environment. Read [this post](http://anbasile.github.io/programming/2017/06/25/jupyter-venv/) on how to run Jupyter notebooks in virtualenvs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup\n",
    "\n",
    "### Dowload pre-trained Inception-v3 model\n",
    "\n",
    "```sh\n",
    "\n",
    "curl http://download.tensorflow.org/models/inception_v3_2016_08_28.tar.gz -o OUTFILE\n",
    "tar -xvf OUTFILE\n",
    "mv inception_v3.ckpt CHECKPOINT_DIR\n",
    " \n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from io import BytesIO\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "import tensorflow.contrib.slim as slim\n",
    "import tensorflow as tf\n",
    "from tensorflow.contrib.slim.nets import inception\n",
    "\n",
    "import numpy as np\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify import:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "eval = slim.evaluation.evaluate_once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set constants and reset previously trained graphs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "checkpointfile = '/Users/andreashelfenstein/InceptV3-trained/inception_v3.ckpt'\n",
    "im_size = 299 # Height and width of images for Inception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create session and load pre-trained network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()\n",
    "\n",
    "inception.inception_v3.default_image_size = im_size\n",
    "inception_v3 = inception.inception_v3\n",
    "arg_scope = inception.inception_v3_arg_scope()\n",
    "inputs = tf.placeholder(tf.float32, (None, im_size, im_size, 3))\n",
    "\n",
    "with slim.arg_scope(arg_scope):\n",
    "    logits, end_points = inception_v3(inputs, num_classes=1001,\n",
    "                                                         is_training=False)\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "saver.restore(sess,checkpointfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the plaintext labels (1000 + 1) for the ImageNet dataset from [here](https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "labels = pickle.load(urllib.request.urlopen('https://gist.githubusercontent.com/yrevar/6135f1bd8dcf2e0cc683/raw/d133d61a09d7e5a3b36b8c111a8dd5c4b5d560ee/imagenet1000_clsid_to_human.pkl') )\n",
    "labels[1001] = 'unused background'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prediction function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(img_array):\n",
    "    \"\"\"\n",
    "    Predict image content with a pre-trained Inception-V3 network.\n",
    "    img_array (np.array): image as numpy array of dimensions 299 * 299 * 3. \n",
    "                            RGB values are between 0 and 1 (not 255), so rescale if\n",
    "                            necessary\n",
    "    Returns:\n",
    "    predictions(dict):   Predictions for each class\n",
    "    \n",
    "    See labels here:\n",
    "    https://gist.github.com/yrevar/942d3a0ac09ec9e5eb3a\n",
    "    \"\"\"\n",
    "    \n",
    "    img_array = img_array.reshape(-1,299,299,3)\n",
    "    predict_values, logit_values = sess.run([end_points['Predictions'], logits], feed_dict={inputs: img_array})\n",
    "    return {'predict_values': predict_values, 'logit_values': logit_values}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Instagram API\n",
    "\n",
    "\n",
    "In order to use the API, you need an Instagram account and a registered client to call the API endpoints.\n",
    "\n",
    "**Register as a developer**\n",
    "\n",
    "[https://www.instagram.com/developer/register/]\n",
    "\n",
    "\n",
    "\n",
    "The API uses OAuth to authorize access. Your client/app has both a **client_id** and a **client_secret**, which you can both get from the Developer page >> [manage clients](https://www.instagram.com/developer/clients/manage/) >> Manage.\n",
    "\n",
    "Also make sure to activate *public_scope* somewhere.\n",
    "\n",
    "You also need a **redirect_uri**; a website to which the user is redirected to after authenticating. In this example, you can just use [localhost](localhost:5000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client_id = \"CLIENT_ID\"\n",
    "client_secret = \"CLIENT_SECRET\"\n",
    "redirect_uri = \"localhost:5000\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step 1: Get Code**\n",
    "\n",
    "The request returns a website, which you can save on your local machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url = \"https://api.instagram.com/oauth/authorize/?client_id=%s&redirect_uri=%s&response_type=code&scope=public_content\" % (client_id, redirect_uri)\n",
    "response = requests.get(url)\n",
    "with open('ig_OAuth.html', 'w') as f:\n",
    "    f.write(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Open the file [ig_OAuth.html](file:///ig_OAuth.html) in your browser, enter your credentials and submit. If the submission fails, make sure the url in the address bar starts with _instagram.com_ and not _file:///_ or _localhost:_.\n",
    "\n",
    "You are then redirected to *localhost:5000?code=YOUR_CODE*. Copy-paste the code into your code.\n",
    "\n",
    "> N.B. there are probably better ways to achieve that, but for now let's just go with it\n",
    "\n",
    "**Step 2: Use code to get access token**\n",
    "\n",
    "Once you have your code, send the following POST request to get your access token:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "code = \"YOUR_CODE\"\n",
    "url =  \"https://api.instagram.com/oauth/access_token\"\n",
    "payload = {\"client_id\": client_id,\n",
    "    \"client_secret\": client_secret,\n",
    "    \"grant_type\": 'authorization_code',\n",
    "    \"redirect_uri\": redirect_uri,\n",
    "    \"code\":code}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.post(url, payload)\n",
    "id_token = response.json()\n",
    "token = id_token['access_token']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you have a token to authenticate all your future requests. You can use it to get all images tagged with 'food', for example:\n",
    "\n",
    "> N.B. As long as your client is in sandbox mode, you can only retrieve photos you have uploaded yourself\n",
    "\n",
    "**Step 3: Load tagged photos**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tag = \"food\"\n",
    "\n",
    "url = \"https://api.instagram.com/v1/tags/%s/media/recent?access_token=%s\" % (tag, token)\n",
    "response = requests.get(url)\n",
    "content = response.json()\n",
    "image_urls = [post['images']['low_resolution']['url'] for post in content['data']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load images and feed to the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import imshow\n",
    "%matplotlib inline\n",
    "\n",
    "for e, image_url in enumerate(image_urls):\n",
    "    response = requests.get(image_url)\n",
    "    img = Image.open(BytesIO(response.content))\n",
    "    img = img.resize((im_size, im_size))\n",
    "    img = img.convert('RGB')\n",
    "    data = np.asarray(img, dtype=np.float32)\n",
    "    data /= 255\n",
    "    predictions = predict(data)\n",
    "    predicted_label = labels[predictions['predict_values'].argmax()]\n",
    "    imshow(data)\n",
    "    print('Prediction for image %s: %s' % (e, predicted_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python_TensorFlow",
   "language": "python",
   "name": "python_tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
